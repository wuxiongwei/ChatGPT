这是一个爱好者主要聚焦商业角度的讨论、观察和笔记。信息主要来自以下渠道： OpenAI的论文（摘要） Sam Altman在How I Built This和Greylock的采访 互联网各种ChatGPT x Generative AI有趣场景集锦 信源的信息总结 @Yiqin_Fu @Diiiii @Ben Thompson

# AIGC最广泛认同的两种场景

1. 对初级白领工作的替代（律师，数据分析师、视频剪辑、平面设计、游戏建模师，甚至程序员、视频博主）
2. 对白领工作的替代

语义理解→分析

文案写作 比如给项目方写拒信…（Twitter@TurnerNovak） 不过对情感要求较高的场景，请谨慎使用AI_(:_」∠)_ 游戏建模 Stable Diffusion 30s生成游戏中的模型… 画师/设计师替代 装修概念图：ChatGPT→Mid Journey 生成程序/debug 但是理想很丰满，现实很骨感… 法律文件整理（初级律师替代）… 尽管目前的AI在画面和文字生成上都有很多bug，但人类仍然乐此不疲。一个很明显的现象是，人们在AI问题上扮演的角色不是审问者，而是编辑者。

# 1. 对白领工作的替代

![img](./assets/(null)-20230223083238961.(null))

![img](./assets/(null)-20230223083238965.(null))

不过对情感要求较高的场景，请谨慎使用AI_(:_」∠)_

Stable Diffusion [30s生成 ](https://twitter.com/emmanuel_2m/status/1599655064217718785?s=20&t=4LFTkjJ3gH1IbdcxrkbZlA)游戏中的模型…

![img](./assets/(null)-20230223083246583.(null))

![img](./assets/(null)-20230223083246985.(null))

[装修概念图 ](https://twitter.com/GuyP/status/1598020781065527296/photo/2)：ChatGPT→Mid Journey

尽管目前的AI在画面和文字生成上都有很多bug，但人类仍然乐此不疲。一个很明显的现象是，人们在AI问题上扮演的角色 ***不是审问者，而是编辑者*** 。

2. 对信息、娱乐、艺术创作的改变

AI生成的游戏：设定&形象一条龙服务 AI游戏（设定+概念图生成）：ChatGPT→Mid Journey（weibo @CheeseWhisper） AI生成画面的资产化： Adobe允许AIGC交易的新规

# 2. 对信息、娱乐、艺术创作的改变

AI游戏（设定+概念图生成）：ChatGPT→Mid Journey（weibo @CheeseWhisper）

![img](./assets/(null)-20230223083238967.(null))

![img](./assets/(null)-20230223083239090.(null))

![img](./assets/(null)-20230223083247023.(null))

![img](./assets/(null)-20230223083246084.(null))

OpenAI ：历史，现在和未来

OpenAI的历史 2015 OpenAI是一个人工智能(AI) 研究实验室，由营利性公司OpenAI LP及其母公司非营利性OpenAI Inc 组成。 该组织于2015年底由埃隆·马斯克（Elon Musk），萨姆·奥尔特曼（Sam Altman）和其他人在旧金山成立，他们共同承诺投入10亿美元。马斯克于2018年2月卸任董事会职务，但仍然是捐助者。 2019 从非营利性转变为“有上限”的营利性，任何投资的利润上限都设置为 100 倍。该公司向其员工分配股权并与微软公司合作，微软公司宣布向该公司投资10 亿美元。随后，OpenAI 宣布打算对其技术进行商业许可，微软是其首选合作伙伴。 2020.06 OpenAI 发布了GPT-3，这是一种基于互联网上数万亿个单词进行训练的语言模型。它还宣布了一个关联的API，简称为“API”，将构成其第一个商业产品的核心。GPT-3 旨在自然语言回答问题，但它也可以在语言之间进行翻译并连贯地生成即兴文本。 2021.01 OpenAI 推出了DALL-E。一年后，他们的最新系统 DALL·E 2 生成了更逼真、更准确的图像，分辨率提高了 4 倍。 2022.10 据The Information报道，OpenAI在考虑向微软要求融更多钱（估值200亿美元） 2022.11 发布ChatGPT，支持多轮语义模型

# OpenAI ：历史，现在和未来

|      |         |                                                              |
| ---- | ------- | ------------------------------------------------------------ |
|      | 2015    | **OpenAI** 是一个人工智能(AI) 研究实验室，由营利性公司 **OpenAI LP** 及其母公司非营利性 **OpenAI Inc 组成。**  该组织于2015年底由埃隆·马斯克（Elon Musk），萨姆·奥尔特曼（Sam Altman）和其他人在旧金山成立，他们共同承诺投入10亿美元。马斯克于2018年2月卸任董事会职务，但仍然是捐助者。 |
|      | 2019    | 从非营利性转变为“有上限”的营利性，任何投资的利润上限都设置为 100 倍。该公司向其员工分配股权并与微软公司合作， **微软公司宣布向该公司投资10 亿美元** 。随后，OpenAI 宣布打算对其技术进行商业许可，微软是其首选合作伙伴。 |
|      | 2020.06 | OpenAI 发布了GPT-3，这是一种基于互联网上数万亿个单词进行训练的语言模型。它还宣布了一个关联的API，简称为“API”，将构成其第一个商业产品的核心。GPT-3 旨在自然语言回答问题，但它也可以在语言之间进行翻译并连贯地生成即兴文本。 |
|      | 2021.01 | OpenAI 推出了DALL-E。一年后，他们的最新系统 DALL·E 2 生成了更逼真、更准确的图像，分辨率提高了 4 倍。 |
|      | 2022.10 | 据The Information报道，OpenAI在 [考虑向微软要求融更多钱 ](https://www.theinformation.com/articles/openai-valued-at-nearly-20-billion-in-advanced-talks-with-microsoft-for-more-funding)（估值200亿美元） |
|      | 2022.11 | 发布ChatGPT，支持多轮语义模型                                |

OpenAI 语言模型的演变

来自真格基金@林惠文的分享👇 也就是说， GPT 1 / 2 / 3：预测人类下一步要说什么（无监督学习） InstructGPT：给出符合人类审美的AI回答 ChatGPT：加入多轮对话，让AI可以实时接收用户的反馈，获得人类最满意的回答

# OpenAI 语言模型的演变

- **GPT 1 / 2 / 3：** 预测人类下一步要说什么（无监督学习）
- **InstructGPT** ：给出符合人类审美的AI回答
- **ChatGPT** ：加入多轮对话，让AI可以实时接收用户的反馈，获得人类最满意的回答

监督学习，无监督学习，强化学习

Fine Tune: 监督学习 其中，GPT-3的训练花了570GB的数据。而对GPT-3进行fine tuning则可能用370kb的数据收获很好的结果 因此，实际上，GPT-3的使用者可以通过收集「参考答案」给AI投喂，从而对模型进行fine tuning，大幅提升对应方向的模型效果 Fine tuning案例 ：AI纳税助手，用户反馈分析，定制化学习 Instruct GPT: 监督学习+强化学习 首先，引入人工给出一些标准答案，让GPT-3学习「如何更好地说话」（fine tuning） 然后，搞一个奖励模型——让机器生成很多答案，人工排序，让机器学习这个排序的逻辑，懂得什么是说得好，什么是说得烂。 最后，把fine tuned的GPT-3模型用奖励模型进行训练：一个model告诉另一个model你做得好还是不好，然后自我迭代。 ChatGPT: 跟InstructGPT逻辑相似，唯一的区别在于ChatGPT基于GPT3.5（InstructGPT的一部分） 局限 技术转变：从较为局限（但easy）的监督学习转向较为开放的无监督学习（GPT系列都是），再引入监督学习和强化学习来调整模型。（人的引入早已有之，GPT-1/2都有监督学习的fine tuning，但是这次引入强化学习才是比较大的创新）

监督学习，无监督学习，强化学习

监督学习是一种机器学习方法，它通过对带有正确答案的训练数据进行学习来预测新数据的输出。举个例子，假设你要训练一个模型来识别不同种类的水果。在监督学习中，你需要提供一大堆带有标签的图片，每张图片都标注了这是哪种水果，比如“苹果”或“香蕉”。然后你的模型会根据这些训练数据来学习如何识别不同种类的水果。（推荐算法） 无监督学习是另一种机器学习方法，它不需要提供带有正确答案的训练数据。相反，它只需要一大堆原始的输入数据，然后通过对数据的分析来发现数据之间的关系和模式。举个例子，假设你有一大堆未标记的图片，你可以使用无监督学习来训练一个模型来发现这些图片中出现最多的特征，比如颜色或形状。你的模型可能会发现许多图片都是圆形的，而且大部分图片都是绿色的。（GPT-3） 强化学习是另一种机器学习方法，它通过试错和反馈机制来让模型学习如何完成特定的任务。强化学习的目标是通过反复尝试来找到最优解，从而让模型在完成任务时获得最大的奖励。举个例子，假设你要训练一个模型来玩俄罗斯方块游戏。在强化学习中，你的模型会不断尝试移动方块，直到完成一个得分最高的游戏。每次移动都会得到一定的奖励或惩罚，比如得分高就会得到正的奖励，游戏失败就会得到负的惩罚。通过不断尝试和反馈，你的模型可以学习如何完成这个任务，从而获得最大的奖励。（AlphaGo） （以上内容来自ChatGPT）

### Fine Tune: 监督学习

- 因此，实际上，GPT-3的使用者可以通过收集「参考答案」给AI投喂，从而对模型进行fine tuning，大幅提升对应方向的模型效果

Fine tuning案例 ：AI纳税助手，用户反馈分析，定制化学习

Keeper Tax帮助独立承包商和自由职业者纳税。在客户链接他们的财务账户后，Keeper Tax 使用各种模型来提取文本并对交易进行分类。使用分类数据，Keeper Tax 可以识别容易遗漏的税务注销，并帮助客户直接从应用程序中报税。通过定制 GPT-3，Keeper Tax 能够不断改进结果。Keeper Tax 每周添加一次大约 500 个新的训练示例来微调他们的模型，这导致每周准确率提高约 1%，准确率从 85% 提高到 93%。 Viable帮助公司从客户反馈中获得洞察力。通过定制 GPT-3，Viable 能够将大量非结构化数据转换为可读的自然语言报告，突出显示最重要的客户投诉、赞美、请求和问题。定制 GPT-3 提高了 Viable 报告的可靠性。通过使用定制版的 GPT-3，总结客户反馈的准确率从 66% 提高到 90%。结果是客户在做出产品决策时需要的有形、直观的信息。 Sana Labs是人工智能学习开发和应用的全球领导者。Sana 学习平台利用最新的 ML 突破为每个人定制内容，为企业提供个性化学习体验。通过使用他们的数据定制 GPT-3，Sana 的问题和内容生成从语法正确但一般的回答到高度准确的输出。这产生了 60% 的改进，从根本上为他们的学习者提供了更加个性化和有效的体验。

### Instruct GPT: 监督学习+强化学习

首先，引入人工给出一些标准答案，让GPT-3学习「如何更好地说话」（fine tuning）

然后，搞一个奖励模型——让机器生成很多答案，人工排序，让机器学习这个排序的逻辑，懂得什么是说得好，什么是说得烂。

最后，把fine tuned的GPT-3模型用奖励模型进行训练：一个model告诉另一个model你做得好还是不好，然后自我迭代。

![img](./assets/(null)-20230223083240190.(null))

![img](./assets/(null)-20230223083239446.(null))

ChatGPT: 跟InstructGPT逻辑相似，唯一的区别在于ChatGPT基于GPT3.5（InstructGPT的一部分）

![img](./assets/(null)-20230223083239712.(null))

![img](./assets/(null)-20230223083240025.(null))

局限

ChatGPT 有时会写出看似合理但不正确或荒谬的答案。解决这个问题具有挑战性，因为： (1)在 RL 训练期间，目前没有真实信息来源； (2) 训练模型更加谨慎导致它拒绝可以正确回答的问题； (3) 监督训练会误导模型，因为理想的答案取决于模型知道什么，而不是人类演示者知道什么。 ChatGPT 对输入措辞的调整或多次尝试相同的提示很敏感。例如，给定一个问题的措辞，模型可以声称不知道答案，但只要稍作改写，就可以正确回答。 该模型通常过于冗长并过度使用某些短语，例如重申它是 OpenAI 训练的语言模型。这些问题源于训练数据的偏差（训练者更喜欢看起来更全面的更长答案）和众所周知的过度优化问题。1 2 理想情况下，当用户提供模棱两可的查询时，模型会提出澄清问题。相反，我们当前的模型通常会猜测用户的意图。 虽然我们已努力使模型拒绝不当请求，但它有时会响应有害指令或表现出有偏见的行为。我们正在使用Moderation API来警告或阻止某些类型的不安全内容，但我们预计它目前会有一些漏报和漏报。我们渴望收集用户反馈，以帮助我们正在进行的改进该系统的工作。

**技术转变** ：从较为局限（但easy）的监督学习转向较为开放的无监督学习（GPT系列都是），再引入监督学习和强化学习来调整模型。 *（人的引入早已有之，GPT-1/2都有监督学习的fine tuning，但是这次引入强化学习才是比较大的创新）*

ChatGPT：实际成本和应用

OpenAI 前置成本：数据成本（收集、标签、清洗），模型训练算力成本，人力成本etc. 使用成本：（感觉可以估个价，比2美分高，12美分低） 定价（来自OpenAI API Pricing）： 使用OpenAI最强大的语言模型Davinci（GPT-3.5系列）：750字 2美分 使用RLHF调整训练过的语言模型：750字 12美分（可能可以让大家理解，为什么ChatGPT喜欢说话只说一半——它希望你别随随便便让他说下去，经费在燃烧！） p.s. 12.05 ChatGPT的用户数已经突破百万！（每天烧几十万刀，很酸爽）

# ChatGPT：实际成本和应用

- 前置成本：数据成本（收集、标签、清洗），模型训练算力成本，人力成本etc.
- 使用成本：（感觉可以估个价，比2美分高，12美分低）

![img](./assets/(null)-20230223083240172.(null))

![img](./assets/(null)-20230223083247406.(null))

**定价（来自OpenAI API Pricing）：**

- 使用OpenAI最强大的语言模型Davinci（GPT-3.5系列）： **750字 2美分**
- 使用RLHF调整训练过的语言模型： **750字 12美分** *（可能可以让大家理解，为什么ChatGPT喜欢说话只说一半——它希望你别随随便便让他说下去，经费在燃烧！）*

p.s. 12.05 ChatGPT的用户数已经突破百万！ *（每天烧几十万刀，很酸爽）*

![img](./assets/(null)-20230223083240489.(null))

![img](./assets/(null)-20230223083240743.(null))

开源大模型的应用落地：OpenAI的布局

📣 OpenAI Startup Fund(100M): 微软是金主爸爸之一，会对Portfolio给钱给微软Azure的折扣，以及Access to OpenAI的最新研究成果 📣 12.1投资的四个AI项目 Descript：让视频编辑像文字一样简单（产品已经推出） Harvey：法律工作者的research/drafting/analysis工具 Mem：个人助手，收集互联网上最相关的信息，预测你最可能使用的下一个产品 Speak：AI语言老师

# 开源大模型的应用落地：OpenAI的布局

📣 **OpenAI Startup Fund(100M):** 微软是金主爸爸之一，会对Portfolio给钱给微软Azure的折扣，以及Access to OpenAI的最新研究成果

- Descript：让视频编辑像文字一样简单（产品已经推出）
- Harvey：法律工作者的research/drafting/analysis工具
- Mem：个人助手，收集互联网上最相关的信息，预测你最可能使用的下一个产品

AI小工具：其它相关项目

Base 10 AI趋势 Jasper.ai: 陈词滥调广告生成 Stable Diffusion的潜在场景：to大B SaaS，小B优化创业公司的支出结构 Descript: 让视频/音频的剪辑像文字处理一样简单 Notion.AI From ex GitHub CEO: 市面上AI的应用场景出现了“断层”，主要源于大家都想模仿OpenAI的Bell Labs模式，自己训练大模型。实际上大模型的训练难度大、经费需求高，真正能够push the limits的项目可能是那些落地应用，并持续给大模型反馈提升的项目。

# AI小工具：其它相关项目

![img](./assets/(null)-20230223083246919.(null))

![img](./assets/(null)-20230223083247063.(null))

Jasper.ai: 陈词滥调广告生成

据说八个月做到 $40m 年收入，是史上增长最快的 SaaS。Jasper.ai 提供的服务就是自动生成（陈词滥调式的）社交媒体广告语、产品博客内容。

Stable Diffusion的潜在场景：to大B SaaS，小B优化创业公司的支出结构

Stability.AI（Stable Diffusion母公司）的CEO认为，生成模型更像是咨询公司而不是 SaaS 公司。Disney、Sony 这样的公司需要根据他们自己的版权内容来生成新内容，但他们并不愿意自己的版权内容流出，所以 Stable Diffusion 这样的公开模型提供一个基础，他们再在此基础上销售 finetune 模型的咨询服务。

Descript: 让视频/音频的剪辑像文字处理一样简单

除了用编辑文本的方式编辑音频/视频，还加入了自动提升音效等功能。

Notion.AI

虽然质量可能不如ChatGPT，但用户能从怎样的角度感觉到差别呢？大模型的应用可能还是渠道为王——谁拥有流量，谁就拥有用户，拥有潜在的收入场景。Introducing Notion AI

From [ex GitHub CEO ](https://stratechery.com/2022/an-interview-with-daniel-gross-and-nat-friedman-about-the-democratization-of-ai/): 市面上AI的应用场景出现了“断层”，主要源于大家都想模仿OpenAI的Bell Labs模式，自己训练大模型。实际上大模型的训练难度大、经费需求高，真正能够push the limits的项目可能是那些落地应用，并持续给大模型反馈提升的项目。

关于未来，可能的方向？

数据→算法→应用 实现更好的模型需要的资源？数据的资产化，大量、干净、高质量的数据最为难得（可能跟crypto相关） 大模型算法的训练？去中心化算力（可能跟Crypto相关） 潜在的创业市场？利用开源大模型调整参数产品化是更省钱省力的路径（Sam Altman） 会不会取代搜索引擎？（基于ChatGPT的现有能力）

# 关于未来，可能的方向？

### **数据→算法→应用**

- **实现更好的模型需要的资源？** 数据的资产化，大量、干净、高质量的数据最为难得（可能跟crypto相关）
- **大模型算法的训练？** 去中心化算力（可能跟Crypto相关）
- **潜在的创业市场？** 利用开源大模型调整参数产品化是更省钱省力的路径（Sam Altman）

会不会取代搜索引擎？（基于ChatGPT的现有能力）

搜索上，AI能做的是：匹配他认为的最佳结果（且经过他自己的内化），很可能是错的（这一版没加fact check），一本正经地胡说八道。 所以如果要： a)找到某个确切信息源，不应该找AI b)找一个很难有确切信息源融合的东西，可以找AI（比如给代码debug找思路） 但实际上，AI 做的事情就是pattern matching: 从自己的数据库里找到最佳结果，提取总结融合，这个过程跟搜索的逻辑非常相似。但由于出现了「提取总结融合」这个环节，可能会出错。

我们可以期待什么？

GPT-4： 可能并不在于极大的训练参数和训练成本，而在于更接近人类神经活动方式的构造和更好的算法 可能是multi-media输入，接收文字、语音、视频、图像等输入

# 我们可以期待什么？

- 可能并不在于极大的训练参数和训练成本，而在于更接近人类神经活动方式的构造和更好的算法
- 可能是multi-media输入，接收文字、语音、视频、图像等输入

或者更多的未来

加入fact check约束的Chatbot 联网：未来的模型一定是动态中进化的，而不是训练结束之后就与互联网隔绝了（潜在的内容版权问题能否由crypto解决？） Sam Altman对未来的畅想： AI不仅能帮你整理每天的task，还能帮你做出最合理的回复，完成所有你打算完成的任务…人类的功能可能不再是执行，而是思考和提问 未来能源和智能的边际成本将无限趋近于0 “My basic model of the next decade is that the marginal cost of intelligence and the marginal cost of energy are going to trend rapidly towards zero, surprisingly far”，这将对社会造成翻天覆地的影响，因为目前的社会分工极大部分建立在能源和智能的成本结构之上 大量劳动的价值归零——新世界的价值分配？个人如何构建自己的独特价值？ AI不会改变社会的哪方面？所有深层次的生物学方面的事情，我认为我们仍然会非常关心与他人的互动，我们仍然会玩得很开心，我们大脑的奖励系统仍然会以同样的方式运作，我们仍然会有同样的动力去创造新事物，为愚蠢的地位而竞争，组建家庭等等。所以我认为 100 年后出现的某些东西更可能是 5 万年前人们在关心的，而不是 100 年前关心的。 重要的永远是想法的质量和对你想要的东西的理解。

- 联网：未来的模型一定是动态中进化的，而不是训练结束之后就与互联网隔绝了（潜在的内容版权问题能否由crypto解决？）

- AI不仅能帮你整理每天的task，还能帮你做出最合理的回复，完成所有你打算完成的任务…人类的功能可能不再是执行，而是思考和提问
- **未来能源和智能的边际成本将无限趋近于0** “My basic model of the next decade is that the marginal cost of intelligence and the marginal cost of energy are going to trend rapidly towards zero, surprisingly far”，这将对社会造成翻天覆地的影响，因为目前的社会分工极大部分建立在能源和智能的成本结构之上
- 大量劳动的价值归零——新世界的价值分配？个人如何构建自己的独特价值？
- AI不会改变社会的哪方面？所有深层次的生物学方面的事情，我认为我们仍然会非常关心与他人的互动，我们仍然会玩得很开心，我们大脑的奖励系统仍然会以同样的方式运作，我们仍然会有同样的动力去创造新事物，为愚蠢的地位而竞争，组建家庭等等。所以我认为 100 年后出现的某些东西更可能是 5 万年前人们在关心的，而不是 100 年前关心的。 重要的永远是想法的质量和对你想要的东西的理解。

和更近的现在

AI商务写作和整理的助手 generative AI让游戏（图像层和语言层，但是逻辑层还是人类在行）、音乐的生成更简单 ChatGPT的代码教学：更多不会写代码的用户，可以更简单地念咒语施魔法 “提问的能力”比“理解和总结”更重要

- generative AI让游戏（图像层和语言层，但是逻辑层还是人类在行）、音乐的生成更简单
- ChatGPT的代码教学：更多不会写代码的用户，可以更简单地念咒语施魔法