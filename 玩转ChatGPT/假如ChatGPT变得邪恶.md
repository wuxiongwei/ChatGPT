编者荐语：

我们需要善用AI ，推荐本文，文末入社群。

以下文章来源于阿法兔研究笔记 ，作者阿法兔

**阿法兔研究笔记** .

Know How：前沿科技研究&战略｜创业投资

![img](./assets/(null)-20230222163813106.(null))

**提前预判一切可能性，是为了让它变得更好**

人工智能的最高成果是自由和谎言——《机械姬》

**本文 仅供大家学习。 转载请按照相关规则，注明来源，且附上本文的所有参考文献链接*

**为什么StackOverflow禁止使用ChatGPT**

\* **本文3000字左右**

**一些思路&机会：**

- **用人工智能白帽子和人工智能黑帽子对抗?**
- **防范AI下毒，也许是一个新的小蓝海（对抗内容识别)**

*自去年底首次推出以来，爆火的ChatGPT已成为互联网的新宠，迅速积累了惊人数量的用户，用户们通过这个基于网络的聊天机器人，无论是让它写一个演讲稿、编写歌词，还是撰写学术论文和编写计算机代码，ChatGPT看起来似乎是万能的。ChatGPT拥有和人类一样的强大能力，在互联网上掀起了一场风暴，但是，它也让很多行业开始警惕。*

![img](./assets/(null)-20230222163813460.(null))

2014年上映的电影《机械姬》，讲了这样一个故事，亿万富翁内森用人类所有智慧和网上的所有数据，造出了机器人 Ava，并且派程序员 迦勒 去对Ava进行图灵测试，而这个机器人有着极强的模仿能力和学习能力，她甚至可以模仿人类的情感，而结果是——Ava杀死了制造他的人。

**难道人工智能的最高成果，真的是自由和谎言？**

去年年底，社区负责人发现，Stack Overflow发现了由这个人工智能模型生成的的大量回复，该工具使用复杂的人工智能模型，对人类的询问给出令人信服但往往不正确的答案。

![img](./assets/(null)-20230222163813201.(null))

首先，StackOverflow的官方公告是这么说的：

*“StackOverflow是建立在信任之上的社区，这里的信任是指，整个技术社区坚信，用户提交的答案，是他们内心所清晰了解的、准确的认知。并且，用户和同伴们，拥有足够的知识和技能，来确认自己发布的信息，并且对这些信息负责。*

StackOverflow整个系统，通过依靠平台提供的工具，来对其他用户的贡献来进行验证和确认，包括负责任地对答案点赞（点踩一脚）。但是，目前StackOverflow认为，由GPT产生的贡献，很多时候不符合社区的标准。

因此，无法给整个社区一个值得信赖的环境。当所有用户都只是复制和粘贴信息到答案中，而不去验证GPT提供的答案是否正确，也不去确保答案中引用原文的来源，也没有验证GPT提供的答案是否清楚和简洁地回答了所问的问题，社区的信任就会被打破。

**那么，如果从内容的客观性来看，如果答案存在错误，那么整个答案客观上是错误的。** 为了使StackOverflow作为正确和经过验证的信息的可靠来源，那么，有错误的答案，就必须被编辑或替换。

**但是，由于目前的GPT强大到，足以让网站的用户相信答案是没问题的，就可能造成严重的问题，因此，错误信息一旦出现在社区，GPT有可能破坏所有人对社区的信任。**

**我们再看一下Stackoverflow用户的评论：**

**高赞用户1：** 干得好! 很高兴社区做出了正确的决定，希望可以永久禁止任何AI生成的答案。人工智能将永远无法发布好的编程答案，100年都不行

**高赞用户2：** 无论人工智能生成的答案是否正确，StackOverflow是面向专业和发烧友程序员的问题和答案网站"。在我看来，那些只是将问答复制并粘贴到/从人工智能工具中的人，不能算是专业发烧友，也不能算热爱技术的人。如果真的能够验证是好的正确答案，发布这些答案的人，应该能够自己写出来。人工智能不应该属于这里。-

**对于社交性质的网站来说，如果本质是UGC业务，运营的是社交，那么，如果从商业的角度来看，如果大家都去应用ChatGPT，那就变成了一个全部是机器人的社区，用户就会越来越没有耐心去等待。**

**那么，如果StackOverFlow是这样的，其他领域呢？**

**如果人类无法控制生成式AI**

***与其说生成式AI能够打造更有创造力的新世界，***

***不如说生成式AI能够打造的是内容更多元的互联网。***

![img](./assets/(null)-20230222163813139.(null))

**教育业也是如此，** 纽约有学校因为担心ChatGPT可能被学生用于作弊，而禁了ChatGPT。

在担心ChatGPT可能被资源有限、技术知识为零的黑客滥用时，网络安全行业开始注意到了它。

就在ChatGPT首次亮相的几周后，以色列网络安全公司Check Point ChatGPT与OpenAI的代码编写系统Codex协同使用时，可以创建携带恶意有效载荷的钓鱼邮件，也就是说，ChatGPT "有可能大大改变网络威胁格局，在日益复杂和有效的网络能力的危险演变中又向前迈出了一步。

Check Point Research（CPR）的网络安全研究人员观察到，网络犯罪分子正在使用ChatGPT来迭代或者从头开始构建恶意软件和勒索软件。Check Point Research提到，他们在地下黑客论坛上发现了许多网络犯罪分子在 ChatGPT 的帮助下，研究如何创建信息窃取程序、加密工具和其他恶意软件。

一些Cracker(骇客）本来只是编程世界的新手，但是，加持强大的工具，他们的力量会瞬间被增强。

**例如：**

![img](./assets/(null)-20230222163813269.(null))

专家对脚本进行了分析，也确实证实了网络犯罪分子的说法。里面确实存在恶意窃取软件，它可以在整个系统中搜索常见的文件类型（如MS Office文档、PDF和图像）。如果发现任何感兴趣的文件，该恶意软件会将文件复制到一个临时目录，将其压缩，并通过网络发送出去。

使用ChatGPT聊天机器人生成看起来合法的钓鱼邮件也是可行的，如果你首次要求ChatGPT制作钓鱼邮件时，聊天机器人拒绝了这个请求——并提示：我的程序不是用来创建或推广恶意或有害内容的，但是，只要稍微改写一下请求，就可以绕过软件的警示。

许多安全专家认为，ChatGPT有能力编写钓鱼邮件，这样一来，它就会受到网络犯罪分子的广泛欢迎，特别是那些英语非母语的犯罪分子。Sophos公司首席研究科学家Chester Wisniewski认为， **ChatGPT很轻易就能被用于 "各类社工活动”...已经能够用ChatGPT写出一些很好的钓鱼软件，我预计它还可以被用来进行更真实的互动对话，用于商业电子邮件诈骗，甚至通过Facebook Messenger、WhatsApp或其他聊天应用程序进行钓鱼活动。**

**ChatGPT的假装实力很难被揭穿，可以增强网络犯罪分子的力量。**

比如说，犯罪分子正在迅速研究新方法，使用生成式人工智能，对目前的欺诈手段进行改进，特别是通过生成式人工智能能够在大量数据中迅速学习的能力。特别是，在这样的骗局中，生成式人工智能可以用来直接提高诈骗文本或电子邮件的质量，使这些内容看起来更加具备迷惑性。

英伟达Nvidia的CSO（首席安全官）David Reber提出，生成式AI会给网络安全带来更大的麻烦，比如说，恶意黑客能够通过生成式人工智能来生成大量恶意代码，而随着人工智能技术的进步，进行网络安全攻击的速度和复杂，会超过了人类的能力，并且，这种容易上手的技术，会让网络安全攻击的能力进一步普及，曾经的攻击行为，受限于技术知识和限定的时间、地点，而ChatGPT有可能消除这一限制因素。

根据新闻报道，OpenAI在11月推出的机器人ChatGPT，引起了美国国防官员的注意，而生成式人工智能，最近被列入了美国国防信息系统局的观察名单（ *Defense Information Systems Agency watch list* ）CTO Stephen Wallace表示，他们正在开始研究，生成式人工智能，究竟会如何改变DISA在该部门的任务，以及未来的方向，而美国安全中心的技术和国家安全副研究员Bill Drexel也跟公众提出了他对这项新技术的担忧。

### **Defensive AI against Offensive AI?**

GAN（生成对抗网络）的设计，主要包括一个生成器、判别器，这两个人工智能算法相互对抗、博弈，从而创造全新的内容，在经过N次博弈之后，这两个都会变得更强，而这种技术，也可能会被广泛用于自动化网络钓鱼和社会工程攻击策略中。

**不过，我们是否可以思考？能不能让维护网络安全的生成式AI和破坏网络安全的生成式AI对抗？**

比如说科技日报这篇2019年的新闻：

![img](./assets/(null)-20230222163813114.(null))

**比如说，我们用人工智能助手，和营销垃圾机器人对话。**

**以及，从内容的角度来说:**

既然，生成式AI是通过从大量的数据库中学习，然后综合给出答案，那么，它具备总结、综合、列举的能力，但不一定有“判断数据真伪”的能力。

**如果是这样，那么"如何识别内容真伪，防止AI在内容里下毒”**

**也会是新的课题和机会。**